<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="ai-communication-consent" content="No consent is granted to AI applications, agencies, or data brokers to contact me or process my personal data. Request erasure and exclusion from ChatGPT or other AI datasets under EU data rights.">
    <title>Show Me Your Colors | María-Teresa Carmier</title>
    <link rel="icon" type="image/png" href="assets/favicon1.png">
    <meta name="description" content="Show Me Your Colors is a Master's thesis demonstrating policy design for AI systems interacting with vulnerable users. A speculative design engineering project that uses working HRV prototypes to explore how AI governance frameworks can balance child privacy, parental awareness, and ethical intervention.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500&family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="project.css">

    <!-- Microsoft Clarity Analytics -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "tx50823cyl");
    </script>
</head>
<body>
    <nav class="timeline-nav">
        <a href="index.html" class="nav-home">← María-Teresa Carmier</a>
        <div class="nav-arrows">
            <div class="progress-dots">
                <span class="progress-dot active" title="Show Me Your Colors"></span>
                <a href="responsible-ai.html" class="progress-dot" title="Responsible AI"></a>
                <a href="junipers-clompass.html" class="progress-dot" title="Juniper's Clompass"></a>
                <a href="black-eco-feminisms.html" class="progress-dot" title="Black Eco Feminisms"></a>
                <a href="rebrew.html" class="progress-dot" title="ReBrew"></a>
                <a href="art.html" class="progress-dot" title="Art"></a>
            </div>
            <div class="nav-controls">
                <a href="art.html" class="nav-arrow">←</a>
                <span class="project-indicator">1 of 6 | AI Policy Design</span>
                <a href="responsible-ai.html" class="nav-arrow">→</a>
            </div>
        </div>
    </nav>

    <div class="project-container">
        <header class="project-header">
            <div class="project-number">1.</div>
            <h1 class="project-title">Show Me Your Colors</h1>
            <p class="project-subtitle">Master of Design Graduate Thesis Project — UC Berkeley, MDes, 2025</p>
        </header>

        <div class="project-content">
            <h2>Executive Summary</h2>
            <p class="project-summary">
                This case study demonstrates policy design for AI systems interacting with vulnerable users. The project addresses a core tension in AI development: how to provide meaningful support without creating dependency, surveillance, or harm. Through user research with elementary students, I designed a framework that balances child privacy, parental awareness, and AI intervention while accounting for how children actually experience and conceptualize emotions.
            </p>

            <div class="project-meta-grid card-layout-row">
                <article class="meta-card card-pink">
                    <span>Domain</span>
                    <strong>AI Policy Design · Child Privacy · Ethical AI · Education</strong>
                    <p>Designing governance frameworks for AI systems that support vulnerable populations without creating surveillance or dependency.</p>
                </article>
                <article class="meta-card card-pink">
                    <span>Challenge</span>
                    <strong>Privacy vs. Parental Awareness</strong>
                    <p>How to give parents visibility into their child's emotional well-being without creating surveillance that undermines trust or autonomy.</p>
                </article>
                <article class="meta-card card-pink">
                    <span>Approach</span>
                    <strong>Three-Tier Privacy Architecture</strong>
                    <p>Information access levels designed to preserve child autonomy while enabling parental support without interrogation.</p>
                </article>
                <article class="meta-card card-pink">
                    <span>Impact</span>
                    <strong>Policy Framework for Vulnerable Users</strong>
                    <p>Demonstrates that effective AI policy requires understanding human behavior, developmental psychology, and ethics of surveillance vs. support.</p>
                </article>
            </div>

            <h2>The Challenge</h2>
            <p>
                Children experience heightened stress during daily transitions — moving between classes, returning home, processing external events like political elections. While emotional self-awareness is crucial for development, existing approaches either:
            </p>
            <ul>
                <li>Ignore children's internal states entirely</li>
                <li>Create surveillance systems that undermine trust and autonomy</li>
                <li>Pathologize normal emotional responses</li>
            </ul>
            <p><strong>Core Policy Question:</strong> How do you give parents visibility into their child's emotional well-being without creating surveillance that undermines trust or autonomy?</p>

            <h2>Design Decisions: Technology Selection</h2>

            <h3>Why AI Over Physiological Markers</h3>
            <p>
                <strong>Initial approach:</strong> Chromatic stickers that changed color based on cortisol detection
            </p>
            <p>
                <strong>Problem:</strong> Physiological detection alone provided data but no intervention framework. Parents would see stress indicators without understanding context or having tools to respond appropriately.
            </p>
            <p>
                <strong>Solution:</strong> Shifted to HRV-based detection paired with AI-guided breathing exercises. This choice was fundamentally about policy control — AI allowed me to design governance rules for: when to intervene, what language to use, how to prevent dependency, and what information parents should access.
            </p>

            <h2>Policy Framework</h2>

            <h3>Privacy Architecture</h3>
            <p>
                The system implements a three-tier information architecture designed to preserve child autonomy while enabling parental support:
            </p>

            <table style="width: 100%; border-collapse: collapse; margin: 1.5em 0;">
                <thead>
                    <tr>
                        <th style="text-align: left; padding: 0.75em; border-bottom: 2px solid var(--color-pink);">Stakeholder</th>
                        <th style="text-align: left; padding: 0.75em; border-bottom: 2px solid var(--color-pink);">Access Level</th>
                        <th style="text-align: left; padding: 0.75em; border-bottom: 2px solid var(--color-pink);">Rationale</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td style="padding: 0.75em; border-bottom: 1px solid var(--color-pink-light);">Child</td>
                        <td style="padding: 0.75em; border-bottom: 1px solid var(--color-pink-light);">Full AI conversation, real-time breathing prompts, complete interaction history</td>
                        <td style="padding: 0.75em; border-bottom: 1px solid var(--color-pink-light);">Child receives immediate support and maintains control over disclosure</td>
                    </tr>
                    <tr>
                        <td style="padding: 0.75em; border-bottom: 1px solid var(--color-pink-light);">Parent</td>
                        <td style="padding: 0.75em; border-bottom: 1px solid var(--color-pink-light);">Notification: "Feelings were big today" with ice cream visual. NO trigger details, NO conversation content, NO real-time alerts</td>
                        <td style="padding: 0.75em; border-bottom: 1px solid var(--color-pink-light);">Creates opening for gentle inquiry without enabling interrogation or real-time intervention</td>
                    </tr>
                    <tr>
                        <td style="padding: 0.75em;">System</td>
                        <td style="padding: 0.75em;">HRV data, AI prompt logs, intervention patterns</td>
                        <td style="padding: 0.75em;">Enables improvement of AI prompts and safety monitoring</td>
                    </tr>
                </tbody>
            </table>

            <p><strong>Key Policy Principle:</strong> Parents receive enough information to offer support ("I saw you had big feelings") without enough information to interrogate, punish, or override the child's choice to share or not share details.</p>

            <h3>Language Framework</h3>
            <p>
                <strong>Challenge:</strong> Initial user research revealed children associated emotions with Inside Out color coding (red = anger, blue = sadness). During the 2024 election period, children were mapping these colors onto political narratives: red = Trump = anger = "good," blue = Kamala = sadness = "loser."
            </p>
            <p>
                <strong>Discovery moment:</strong> At an ice cream parlor with my sons, watching ice cream melt, I realized this metaphor captured what I needed: temporary, normal, manageable, and politically neutral.
            </p>
            <p>
                <strong>Result:</strong> Shifted from color-coded emotions to "melts" — avoiding both political contamination and pathologizing language like "meltdown" or "episode."
            </p>
            <p>
                Credit to my son, Baby E, for co-creating these playful melting phases and giving the interface its joyful energy.
            </p>
            <div class="icon-grid">
                <div class="icon-item">
                    <img src="https://github.com/user-attachments/assets/1f4070a0-7ea5-45b3-9f30-b47fb52dd361" alt="Full ice cream representing regulated physiological state" width="37" height="71">
                    <span class="icon-label">Regulated</span>
                </div>
                <div class="icon-item">
                    <img src="https://github.com/user-attachments/assets/934e2df0-4424-4915-8a87-91ef47530f2a" alt="Melting ice cream representing transitioning state" width="37" height="61">
                    <span class="icon-label">Transitioning</span>
                </div>
                <div class="icon-item">
                    <img src="https://github.com/user-attachments/assets/4b3216dd-6853-4a14-ba9d-1a4489ca98f0" alt="Melted ice cream representing dysregulated state" width="28" height="47">
                    <span class="icon-label">Dysregulated</span>
                </div>
            </div>

            <h2>Edge Cases & Safeguards</h2>

            <h3>Preventing Misuse</h3>
            <p><strong>Risk:</strong> Parent uses data punitively ("I saw you had a melt today, what did you do wrong?")</p>
            <ul>
                <li><strong>Mitigation:</strong> Zero access to triggers, timing, or conversation content</li>
                <li><strong>Language design:</strong> "Big feelings" frames as information, not alarm</li>
                <li><strong>Normalization:</strong> Frequent melts presented as expected, reducing pressure on child</li>
            </ul>

            <h3>Dependency Prevention</h3>
            <p><strong>Risk:</strong> Child becomes reliant on AI for emotional regulation</p>
            <ul>
                <li><strong>Mitigation:</strong> AI prompts emphasize "you're learning to notice" rather than "let me fix this"</li>
                <li><strong>Scaffolding design:</strong> Prompts gradually reduce frequency as child demonstrates self-regulation</li>
                <li><strong>Human connection:</strong> Parent notification creates opportunity for co-regulation, not AI replacement of human support</li>
            </ul>

            <h3>Crisis Escalation</h3>
            <p><strong>Risk:</strong> Child experiencing genuine crisis that exceeds AI capability</p>
            <ul>
                <li><strong>Detection:</strong> Sustained elevated HRV beyond threshold, specific language patterns</li>
                <li><strong>Response:</strong> System immediately notifies parent/teacher with urgency level</li>
                <li><strong>AI behavior:</strong> Shifts to acknowledgment only, stops intervention attempts</li>
            </ul>

            <h2>User Research Insights</h2>
            <p>
                Conducted emotion mapping exercises with elementary students to understand how children conceptualize and express emotional states. Key findings:
            </p>
            <ul>
                <li><strong>Complex emotion vocabulary:</strong> Children used terms like "disgust," "surprised anger," "mad sad," "fear," indicating sophisticated emotional awareness beyond simple happy/sad binary</li>
                <li><strong>Visual representation variation:</strong> Drawings showed diverse ways of expressing same emotion, confirming need for personalized rather than prescriptive emotional frameworks</li>
                <li><strong>Cultural influence:</strong> Strong influence from Inside Out movie created shared emotional vocabulary but also political contamination during election</li>
                <li><strong>Body awareness:</strong> Children could identify physical sensations ("my tummy feels weird") but needed support connecting these to emotional states</li>
            </ul>
            <p>
                <strong>Design implication:</strong> AI prompts needed to meet children where they are — using their language, validating their experience, and building connection between physical sensation and emotional awareness without imposing adult frameworks.
            </p>

            <h3>Research & Co-Design</h3>

            <figure class="project-figure">
                <img src="https://github.com/user-attachments/assets/48ffffec-25a0-4fac-8080-ac3d57b26101"
                     alt="Show Me Your Colors user research session with students"
                     class="project-image"
                     loading="lazy"
                     width="1200"
                     height="800">
                <figcaption>Participatory design sessions with K-5 students exploring physiological states</figcaption>
            </figure>

            <figure class="project-figure">
                <img src="https://github.com/user-attachments/assets/45df8552-f910-4996-a25a-6ee38c0d76e2"
                     alt="Show Me Your Colors user research documentation"
                     class="project-image"
                     loading="lazy"
                     width="1200"
                     height="800">
                <figcaption>Research documentation of visual metaphor development with students</figcaption>
            </figure>

            <figure class="project-figure">
                <img src="https://github.com/user-attachments/assets/4a195eed-1b91-42b2-9336-c61b0b6db6e2"
                     alt="Show Me Your Colors system schema"
                     class="project-image"
                     loading="lazy"
                     width="1200"
                     height="800">
                <figcaption>System architecture showing AI-assisted HRV monitoring flow</figcaption>
            </figure>

            <details class="process-details">
                <summary><h2>Design & Engineering Process <span class="expand-icon">+</span></h2></summary>
                <div class="process-content">
                    <p><strong>Speculative Design Approach:</strong> This project combines policy design with speculative engineering to explore how AI governance frameworks can be embedded into working prototypes. The physical artifacts serve as design probes to test ethical principles in practice.</p>

                    <p><strong>Research:</strong> Observed how edtech increases monitoring and complexity. Explored HRV monitoring with AI-assisted pattern recognition as health-first alternative to behavior tracking.</p>

                    <p><strong>Co-design:</strong> K-5 students created visual metaphors for physiological states through emotion mapping exercises. Ice cream system (full/melting/melted) emerged as culturally neutral and developmentally appropriate.</p>

                    <p><strong>AI Policy Development:</strong> Built lightweight AI model for HRV interpretation paired with governance rules for intervention timing, language design, dependency prevention, and information access controls.</p>

                    <p><strong>Engineering Implementation:</strong> Arduino HRV wearable with wireless parent remote. System architecture designed to enforce privacy boundaries through technical constraints rather than policy alone.</p>

                    <p><strong>Key tension:</strong> How do we use AI to support children's well-being while protecting privacy and agency? The answer required both policy frameworks and technical implementation that makes violating those policies technically difficult.</p>
                </div>
            </details>

            <h3>Prototyping</h3>

            <figure class="project-figure">
                <img src="https://github.com/user-attachments/assets/ac4ba93c-8ae8-4481-8ca3-f385c519b676"
                     alt="Show Me Your Colors prototyping process"
                     class="project-image"
                     loading="lazy"
                     width="1200"
                     height="800">
                <figcaption>Wearable and parent remote prototyping iterations</figcaption>
            </figure>

            <h3>Final Implementation</h3>

            <figure class="project-figure">
                <img src="https://github.com/user-attachments/assets/7672a06f-fe48-4e15-9a1c-f8ba54bc5cc7"
                     alt="Show Me Your Colors final working system"
                     class="project-image project-image--full"
                     loading="lazy"
                     width="1200"
                     height="800">
                <figcaption>Final HRV wearable system with student and parent components</figcaption>
            </figure>

            <h2>Outcomes & Next Steps</h2>

            <h3>What Worked</h3>
            <ul>
                <li>Privacy architecture successfully balanced parental awareness with child autonomy</li>
                <li>Ice cream metaphor provided culturally neutral, age-appropriate emotional framework</li>
                <li>AI control enabled iterative policy refinement based on real interaction patterns</li>
                <li>Speculative engineering approach demonstrated how policy frameworks can be embedded into technical constraints</li>
            </ul>

            <h3>Open Questions for Scale</h3>
            <ul>
                <li><strong>Cultural adaptation:</strong> How should metaphor and language shift across different cultural contexts?</li>
                <li><strong>Long-term dependency:</strong> At what point does continued AI support shift from scaffolding to crutch?</li>
                <li><strong>Evaluation metrics:</strong> How do we measure success beyond HRV reduction? (Self-reported awareness, behavioral change, parent-child communication quality)</li>
                <li><strong>Edge case coverage:</strong> What happens when child shares AI interaction with peers? When multiple children compare their "melt" frequencies?</li>
            </ul>

            <h3>Key Insight</h3>
            <p>
                This project demonstrates that effective AI policy design requires understanding not just technical capability, but human behavior, developmental psychology, cultural context, and the ethics of surveillance vs. support. The hardest work in building AI for vulnerable populations isn't the algorithm — it's the governance framework that determines when and how that algorithm should intervene.
            </p>
            <p>
                As a speculative design engineering project, Show Me Your Colors uses working prototypes to explore how AI governance can be embedded into technical systems. The physical artifacts serve as probes to test whether ethical principles can be enforced through architecture rather than policy alone, demonstrating that the most effective safeguards combine both technical constraints and thoughtful policy design.
            </p>

            <div class="project-cta">
                <h3>Want to learn more about my work?</h3>
                <div class="cta-buttons">
                    <a href="about.html" class="cta-btn cta-btn-primary">
                        📄 View Full Resume
                    </a>
                    <a href="index.html" class="cta-btn cta-btn-secondary">
                        ← Back to Portfolio
                    </a>
                </div>
            </div>
        </div>
    </div>

    <div class="keyboard-hint">Use ← → keys to navigate</div>

    <footer class="project-footer">
        <span class="project-footer-copy">© 2025 María-Teresa Carmier</span>
        <div class="project-footer-links">
            <a href="mailto:mtcarmier@berkeley.edu">Email</a>
            <a href="https://linkedin.com/in/mtcarmier" target="_blank" rel="noopener">LinkedIn</a>
        </div>
    </footer>

    <script src="project-navigation.js"></script>
</body>
</html>
